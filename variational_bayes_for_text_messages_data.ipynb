{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2025-stats2/blob/main/variational_bayes_for_text_messages_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# variational Bayes for text-messages data"
      ],
      "metadata": {
        "id": "h4JKKB0VFgqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.special import digamma\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "metadata": {
        "id": "o3NyjALj7pYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GD70JDuv7hlW"
      },
      "outputs": [],
      "source": [
        "!wget \"https://raw.githubusercontent.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/data/txtdata.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = 'txtdata.csv'\n",
        "\n",
        "plt.figure(figsize=(12.5, 4))\n",
        "\n",
        "count_data = np.loadtxt(PATH)\n",
        "n_count_data = len(count_data)\n",
        "plt.bar(np.arange(n_count_data), count_data, color=\"#348ABD\")\n",
        "plt.xlabel(\"Time (days)\")\n",
        "plt.ylabel(\"count of text-msgs received\")\n",
        "plt.title(\"Did the user's texting habits change over time?\")\n",
        "plt.xlim(0, n_count_data);"
      ],
      "metadata": {
        "id": "7uLHUYQ37jdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## variational inference"
      ],
      "metadata": {
        "id": "KaAjOyRKGAwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### variational M step"
      ],
      "metadata": {
        "id": "X1XDQEcgGG-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def M_step(count_data, cat_params, gamma_a, gamma_b):\n",
        "  alpha = [gamma_a, gamma_a]\n",
        "  beta = [gamma_b, gamma_b]\n",
        "  n_count_data = len(count_data)\n",
        "  for i in [0, 1]:\n",
        "    for n in range(n_count_data):\n",
        "      temp_sum = 0.0\n",
        "      for tau in range(n_count_data):\n",
        "        if (i == 0 and n < tau) or (i == 1 and n >= tau):\n",
        "          temp_sum += cat_params[tau]\n",
        "      alpha[i] +=  temp_sum * count_data[n]\n",
        "      beta[i] += temp_sum\n",
        "  return alpha, beta"
      ],
      "metadata": {
        "id": "7H2X_iHI9Pj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### variational E step"
      ],
      "metadata": {
        "id": "ugsK9OkhGJ6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def E_step(count_data, alpha, beta):\n",
        "  cat_params = np.zeros(n_count_data)\n",
        "  for tau in range(n_count_data):\n",
        "    cat_params[tau] = (digamma(alpha[0]) - np.log(beta[0])) * count_data[:tau].sum()\n",
        "    cat_params[tau] += (digamma(alpha[1]) - np.log(beta[1])) * count_data[tau:].sum()\n",
        "    cat_params[tau] -= (tau - 1) * alpha[0] / beta[0]\n",
        "    cat_params[tau] -= (n_count_data - tau + 1) * alpha[1] / beta[1]\n",
        "  cat_params -= np.max(cat_params)\n",
        "  cat_params = np.exp(cat_params)\n",
        "  cat_params /= cat_params.sum()\n",
        "  return cat_params"
      ],
      "metadata": {
        "id": "n02Mxj96_Htt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### initialization of hyperparameters and posterior parameters"
      ],
      "metadata": {
        "id": "zqNUg3loGMN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gamma_a = 1.0\n",
        "gamma_b = 1.0 / count_data.mean()\n",
        "cat_params = np.exp(np.random.randn(n_count_data))\n",
        "cat_params /= cat_params.sum()"
      ],
      "metadata": {
        "id": "KNRcTJBMASzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### variational inference"
      ],
      "metadata": {
        "id": "GYYMvJz5GTd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(100):\n",
        "  alpha, beta = M_step(count_data, cat_params, gamma_a, gamma_b)\n",
        "  cat_params = E_step(count_data, alpha, beta)"
      ],
      "metadata": {
        "id": "MSFpuF9iBDOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## posterior sampling"
      ],
      "metadata": {
        "id": "5fM5i8LxF4z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import multinomial, gamma\n",
        "\n",
        "N = 1000\n",
        "tau_samples = multinomial.rvs(1, cat_params, size=N, random_state=42).argmax(1)\n",
        "lambda_1_samples = gamma.rvs(alpha[0], scale=1/beta[0], size=N, random_state=42)\n",
        "lambda_2_samples = gamma.rvs(alpha[1], scale=1/beta[1], size=N, random_state=42)"
      ],
      "metadata": {
        "id": "64uHizdBBgfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12.5, 10))\n",
        "\n",
        "ax = plt.subplot(311)\n",
        "ax.set_autoscaley_on(False)\n",
        "\n",
        "plt.hist(lambda_1_samples, histtype='stepfilled', bins=30, alpha=0.85,\n",
        "         label=\"posterior of $\\lambda_1$\", color=\"#A60628\", density=True)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.title(r\"\"\"Posterior distributions of the variables $\\lambda_1,\\;\\lambda_2,\\;\\tau$\"\"\")\n",
        "plt.xlim([15, 30])\n",
        "plt.xlabel(\"$\\lambda_1$ value\")\n",
        "\n",
        "ax = plt.subplot(312)\n",
        "ax.set_autoscaley_on(False)\n",
        "plt.hist(lambda_2_samples, histtype='stepfilled', bins=30, alpha=0.85,\n",
        "         label=\"posterior of $\\lambda_2$\", color=\"#7A68A6\", density=True)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlim([15, 30])\n",
        "plt.xlabel(\"$\\lambda_2$ value\")\n",
        "\n",
        "plt.subplot(313)\n",
        "w = 1.0 / tau_samples.shape[0] * np.ones_like(tau_samples)\n",
        "plt.hist(tau_samples, bins=n_count_data, alpha=1,\n",
        "         label=r\"posterior of $\\tau$\",\n",
        "         color=\"#467821\", weights=w, rwidth=2.)\n",
        "plt.xticks(np.arange(n_count_data))\n",
        "\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.ylim([0, .75])\n",
        "plt.xlim([35, len(count_data)-20])\n",
        "plt.xlabel(r\"$\\tau$ (in days)\")\n",
        "plt.ylabel(\"probability\");"
      ],
      "metadata": {
        "id": "IZfPshhRFy7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12.5, 5))\n",
        "\n",
        "expected_texts_per_day = np.zeros(n_count_data)\n",
        "for day in range(n_count_data):\n",
        "  ix = day < tau_samples\n",
        "  expected_texts_per_day[day] = (lambda_1_samples[ix].sum()\n",
        "                                   + lambda_2_samples[~ix].sum()) / N\n",
        "\n",
        "plt.plot(range(n_count_data), expected_texts_per_day, lw=4, color=\"#E24A33\",\n",
        "         label=\"expected number of text-messages received\")\n",
        "plt.xlim(0, n_count_data)\n",
        "plt.xlabel(\"Day\")\n",
        "plt.ylabel(\"Expected # text-messages\")\n",
        "plt.title(\"Expected number of text-messages received\")\n",
        "plt.ylim(0, 60)\n",
        "plt.bar(np.arange(len(count_data)), count_data, color=\"#348ABD\", alpha=0.65,\n",
        "        label=\"observed texts per day\")\n",
        "\n",
        "plt.legend(loc=\"upper left\");"
      ],
      "metadata": {
        "id": "bYA6KKSBEEAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Ruu2s0ZERq_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}